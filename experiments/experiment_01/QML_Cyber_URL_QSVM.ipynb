{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QML for Cybersecurity: URL Classification with QSVM (Qiskit)\n",
    "\n",
    "This notebook walks through a tiny, end-to-end experiment:\n",
    "\n",
    "1. **Setup**: Install dependencies in a Python venv or environment with Qiskit and scikit-learn.\n",
    "2. **Data**: Load a small URL dataset (malicious vs benign). A sample `urls_sample.csv` is provided.\n",
    "3. **Features**: Extract simple lexical features from URLs.\n",
    "4. **Baseline**: Train a classical SVM.\n",
    "5. **QML**: Train a QSVM using a quantum kernel (simulated backend).\n",
    "6. **Compare**: Evaluate and discuss.\n",
    "\n",
    "> **Note**: This uses a **simulator** (no QC hardware). The goal is pedagogy: how quantum kernels slot into a familiar ML workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Environment Setup\n",
    "\n",
    "Run these commands in your shell **once** (outside the notebook) to prepare a virtual environment:\n",
    "\n",
    "```bash\n",
    "python3 -m venv qml_env\n",
    "source qml_env/bin/activate\n",
    "pip install --upgrade pip\n",
    "pip install qiskit qiskit-machine-learning scikit-learn pandas numpy matplotlib\n",
    "```\n",
    "\n",
    "If you're in WSL, do the above inside Ubuntu. Then start Jupyter (e.g., `pip install notebook` and `jupyter notebook`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "import os, re, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import inspect\n",
    "\n",
    "try:\n",
    "    from qiskit_aer import AerSimulator\n",
    "except ImportError:\n",
    "    AerSimulator = None\n",
    "\n",
    "if 'AerSimulator' not in globals() or AerSimulator is None:\n",
    "    try:\n",
    "        from qiskit.providers.aer import AerSimulator  # pragma: no cover\n",
    "    except ImportError:\n",
    "        AerSimulator = None\n",
    "\n",
    "try:\n",
    "    from qiskit import Aer  # legacy fallback\n",
    "except ImportError:\n",
    "    Aer = None\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "\n",
    "try:\n",
    "    from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "except ImportError:\n",
    "    from qiskit_machine_learning.kernels import QuantumKernel as FidelityQuantumKernel\n",
    "\n",
    "print(\"Ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load Data\n",
    "If you have your own CSV of URLs, set `CSV_PATH` to that file. Otherwise, use the provided sample `urls_sample.csv` (two columns: `url`, `label`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'urls_sample.csv'  # change to your path if needed\n",
    "if not Path(CSV_PATH).exists():\n",
    "    raise FileNotFoundError(\"CSV not found. Place your dataset or the provided urls_sample.csv next to this notebook.\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Feature Extraction\n",
    "We'll compute a small set of lexical features from each URL. Keep the dimensionality small (\u2264 6) so the simulator remains snappy (feature dimension = number of qubits for the QSVM kernel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUSPICIOUS_TLDS = {'.ru','.tk','.top','.xyz','.zip','.click','.gq','.cn','.pw','.work','.cf','.ga','.ml'}\n",
    "SUSPICIOUS_WORDS = {'login','verify','update','billing','gift','account','reset','secure','wallet','airdrop','claim','prize','invoice','urgent','paypal','bank','office365','security'}\n",
    "\n",
    "def is_ip_domain(url: str) -> int:\n",
    "    # crude: check if host looks like IPv4\n",
    "    m = re.search(r\"://([\\d\\.]+)\", url)\n",
    "    if not m:\n",
    "        return 0\n",
    "    host = m.group(1)\n",
    "    return int(bool(re.match(r\"^(?:\\d{1,3}\\.){3}\\d{1,3}$\", host)))\n",
    "\n",
    "def tld_flag(url: str) -> int:\n",
    "    m = re.search(r\"://([^/]+)\", url)\n",
    "    if not m:\n",
    "        return 0\n",
    "    host = m.group(1).lower()\n",
    "    for t in SUSPICIOUS_TLDS:\n",
    "        if host.endswith(t):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def count_chars(url: str, ch: str) -> int:\n",
    "    return url.count(ch)\n",
    "\n",
    "def contains_words(url: str, words: set) -> int:\n",
    "    lower = url.lower()\n",
    "    return int(any(w in lower for w in words))\n",
    "\n",
    "def has_https(url: str) -> int:\n",
    "    return int(url.lower().startswith('https://'))\n",
    "\n",
    "def url_features(url: str):\n",
    "    return [\n",
    "        len(url),                              # 0 length\n",
    "        sum(c.isdigit() for c in url),        # 1 digits\n",
    "        count_chars(url, '.'),                # 2 dots\n",
    "        count_chars(url, '-'),                # 3 hyphens\n",
    "        has_https(url),                       # 4 https flag\n",
    "        is_ip_domain(url),                    # 5 ip-as-domain\n",
    "        tld_flag(url),                        # 6 suspicious tld\n",
    "        contains_words(url, SUSPICIOUS_WORDS) # 7 suspicious tokens\n",
    "    ]\n",
    "\n",
    "X = np.array([url_features(u) for u in df['url']])\n",
    "y = df['label'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Train/Test Split and Scaling\n",
    "We'll standardize features for classical SVM. For QSVM with a quantum kernel, we'll also use scaled features to keep ranges consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "X_train_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Classical Baseline (SVM)\n",
    "We start with a strong classical baseline: RBF-kernel SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', gamma='scale')\n",
    "svm.fit(X_train_s, y_train)\n",
    "pred = svm.predict(X_test_s)\n",
    "print(\"Classical SVM accuracy:\", (pred == y_test).mean())\n",
    "print(classification_report(y_test, pred, digits=4))\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Quantum Kernel + QSVM (Simulated)\n",
    "\n",
    "We restrict to a small number of features to keep the simulator fast. Select the top `d` dimensions. Try `d = 4` or `d = 6` and observe runtime vs. performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 4  # number of features/qubits for the quantum feature map; try 4 or 6\n",
    "cols = list(range(d))  # take first d features; try other subsets for curiosity\n",
    "Xtr_d = X_train_s[:, cols]\n",
    "Xte_d = X_test_s[:, cols]\n",
    "\n",
    "if AerSimulator is not None:\n",
    "    backend = AerSimulator()\n",
    "elif Aer is not None:\n",
    "    backend = Aer.get_backend('aer_simulator')\n",
    "else:\n",
    "    raise ImportError('Qiskit Aer is not available. Install qiskit-aer to run the quantum section.')\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=d, reps=2)  # try reps=1..3 for depth tradeoffs\n",
    "kernel_params = inspect.signature(FidelityQuantumKernel.__init__).parameters\n",
    "if 'backend' in kernel_params:\n",
    "    qkernel = FidelityQuantumKernel(feature_map=feature_map, backend=backend)\n",
    "elif 'quantum_instance' in kernel_params:\n",
    "    class _LegacyQuantumInstance:\n",
    "        def __init__(self, backend):\n",
    "            self._backend = backend\n",
    "\n",
    "        @property\n",
    "        def backend(self):\n",
    "            return self._backend\n",
    "\n",
    "    qkernel = FidelityQuantumKernel(feature_map=feature_map, quantum_instance=_LegacyQuantumInstance(backend))\n",
    "else:\n",
    "    qkernel = FidelityQuantumKernel(feature_map=feature_map)\n",
    "\n",
    "Ktr = qkernel.evaluate(Xtr_d)\n",
    "Kte = qkernel.evaluate(Xte_d, Xtr_d)\n",
    "\n",
    "qsvm = SVC(kernel='precomputed')\n",
    "qsvm.fit(Ktr, y_train)\n",
    "qpred = qsvm.predict(Kte)\n",
    "print('QSVM accuracy:', (qpred == y_test).mean())\n",
    "print(classification_report(y_test, qpred, digits=4))\n",
    "print(confusion_matrix(y_test, qpred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Compare & Reflect\n",
    "\n",
    "- How do accuracies compare?\n",
    "- How does runtime scale as you increase `d` (qubits) or `reps` (circuit depth)?\n",
    "- Are there particular features that help QSVM more than classical SVM?\n",
    "- What would change if we used a real noisy backend instead of a simulator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Extensions / Homework\n",
    "\n",
    "1. Try different feature subsets instead of the first `d` columns (e.g., choose `[0,2,3,7]`).\n",
    "2. Add n-gram or character-based features (but keep `d` small for QSVM runs).\n",
    "3. Swap the feature map (e.g., `PauliFeatureMap`).\n",
    "4. Try a variational classifier (VQC) with a small ansatz (may be slower).\n",
    "5. Replace the dataset with a real malicious URL corpus and compare trends.\n",
    "6. Profile timing for classical vs QSVM to understand scaling effects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}